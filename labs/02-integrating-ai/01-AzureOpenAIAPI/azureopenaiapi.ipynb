{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Working with the Azure OpenAI API directly\n",
    "\n",
    "In this lab, we will perform a simple call to the Azure OpenAI API. This will prove that everything is setup correctly and working for the rest of the labs.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we need to retrieve values from the `.env` file which we will use to make calls to the Azure OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure OpenAI API Base Endpoint: https://kingfisher-hack.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "RESOURCE_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using the API\n",
    "\n",
    "Now let's call the Azure OpenAI API with a prompt. To do this, we'll need the `id` of the Azure OpenAI deployment that contains our completion model. This should already be setup in the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_ID = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll construct a URL to call so that you can see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://kingfisher-hack.openai.azure.com//openai/deployments/gpt-4o/chat/completions?api-version=2024-07-01-preview\n"
     ]
    }
   ],
   "source": [
    "url = RESOURCE_ENDPOINT + \"/openai/deployments/\" + DEPLOYMENT_ID + \"/chat/completions?api-version=\" + API_VERSION\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see the full URL that we are going to call. This URL will use the specified deployment to call the **chat completions** API.\n",
    "\n",
    "Next, we will call the Azure OpenAI API using the URL above. We pass the API key in the HTTP header. We also send a JSON formatted body as part of the request which contains the *prompt* that we want to use to get a response from the OpenAI model. In this case, our prompt is \"Once upon a time\", which should cause the model to complete the prompt by generating a story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"protected_material_code\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"protected_material_text\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"in a quiet village nestled between rolling hills and lush forests, there was a small bookstore run by an elderly gentleman named Mr. Alden. His bookstore, \\\"Alden's Books & Whispers,\\\" was a beloved spot in the village, known not only for its charming collection of stories but also for the mysterious aura that surrounded it.\\n\\nLegend had it that certain books in the store had the ability to come to life. Perhaps it was just a rumor, or maybe it was the imagination of the children who liked to huddle in corners of the store, lost in tales of adventure and wonder. Nevertheless, there was an undeniable air of magic in Alden's bookstore, where dust floated slowly through streams of sunlight and pages whispered to curious minds.\\n\\nAmong the villagers, there was a young girl named Elara, who visited the bookstore every day after school. Elara loved stories more than anything, and she was especially enchanted by the legends of books coming to life. Over time, she developed a special bond with Mr. Alden, who admired her curiosity and love for reading. He often regaled her with stories of his own adventures, and sometimes, just sometimes, he hinted at the true magic lurking in the corners of his beloved store.\\n\\nOne chilly autumn afternoon, while browsing through the shelves, Elara stumbled upon a dusty old book with a leather cover that read \\\"The Enchanted Voyage.\\\" She gently opened the book, and as if by magic, the room seemed to vibrate with a gentle hum. The illustrations inside began to ripple and glow, and Elara got the distinct feeling that the book wanted her to read its story.\\n\\nAs she turned the pages, she felt as if she was being drawn into the tale. Before she knew it, Elara found herself no longer in the bookstore but aboard a magnificent ship sailing across a starlit sea. The air smelled of salt and adventure, and a friendly crew beckoned her to join them in their quest to discover new worlds and mysteries.\\n\\nElara spent what felt like days aboard the ship, experiencing thrilling adventures, solving riddles, and learning about distant lands and the secrets of the stars. She made friends with the crew, who taught her the ways of the sea and the importance of courage and kindness.\\n\\nEventually, she found herself back in the bookstore, clutching the book tightly to her chest, filled with memories of her incredible journey. Mr. Alden was waiting for her with a knowing smile, as if this was not the first time he had seen someone return from such an adventure.\\n\\n\\\"Did you find what you were looking for?\\\" he asked gently.\\n\\nElara nodded, her eyes wide with wonder and gratitude. \\\"Thank you,\\\" she whispered, knowing that Mr. Alden understood the magic more than anyone.\\n\\nFrom that day on, the village was filled with tales of Elara's adventure, and the whispers in Alden's bookstore grew stronger, calling out to dreamers and adventurers alike. The bookstore and its secrets became even more cherished, a reminder that in a world filled with stories, magic is just waiting to be discovered by those who truly believe.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1733399380,\n",
      "  \"id\": \"chatcmpl-Ab4eSZ9KKUXINbKGXOW6lnP0Kykkw\",\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {}\n",
      "    }\n",
      "  ],\n",
      "  \"system_fingerprint\": \"fp_04751d0b65\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 632,\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"total_tokens\": 644\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r = requests.post(url, headers={\"api-key\": API_KEY}, json={\"messages\":[{\"role\": \"assistant\", \"content\": \"Once upon a time \"}]})\n",
    "\n",
    "print(json.dumps(r.json(), indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the API call will be JSON data similar to the below example. Note that the response has been edited to make it easier to read.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"id\": \"chatcmpl-7wVxE2LNxaY6ZoxcWAmhiyrqaLZgf\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1694180212,\n",
    "  \"model\": \"gpt-35-turbo\",\n",
    "  \"prompt_filter_results\": [\n",
    "    {\n",
    "      \"prompt_index\": 0,\n",
    "      (content filter results removed for brevity)\n",
    "    }\n",
    "  ],\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"finish_reason\": \"stop\",\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \", there was a magical kingdom called Tildor ... )))\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"completion_tokens\": 366,\n",
    "    \"prompt_tokens\": 13,\n",
    "    \"total_tokens\": 379\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Here's some information about some of the more interesting pieces of data contained in that response.\n",
    "\n",
    "Key | Description\n",
    "--- | ---\n",
    "`model` | The model that was used to generate the response to the prompt\n",
    "`content` | This is the response that was generated by the OpenAI model. Note that the response example above was edited to remove most of the output to make it easier to read\n",
    "`finish_reason` | This is the reason that the model stopped generating the response. In this case, `stop` indicates the model determined it had fully completed the response without hitting any limits\n",
    "`completion_tokens` | The number of tokens that were used in generating the response\n",
    "`prompt_tokens` | The number of tokens that were consumed by the prompt\n",
    "`total_tokens` | The total number of tokens that were consumed by the request (`prompt_tokens` + `completion_tokens`)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we used the Azure OpenAI API directly to send a prompt to an OpenAI model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "In the next lab, we will look at using the OpenAI SDK to work with the Azure OpenAI service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "📣 [OpenAI Packages/Libraries](../02-OpenAIPackages/openai.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
